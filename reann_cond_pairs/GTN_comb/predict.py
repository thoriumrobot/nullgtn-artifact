# -*- coding: utf-8 -*-
"""GTN_preprocessing.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fb5XBg4qX2J-jc6grQeXnPhXOnGh9d94
"""

import json
import numpy as np
from scipy.sparse import csr_matrix
import os
import sys
import torch
import pickle
from torch_geometric.utils import add_self_loops
from sklearn.metrics import f1_score as sk_f1_score
from utils import init_seed, _norm
import argparse

def get_batch(graph_json_list, batch_size=8000):
    current_batch = []
    current_size = 0

    for graph_json in graph_json_list:
        nodes = graph_json['nodes']
        node_count = len(nodes)
        if current_size + node_count > batch_size:
            yield current_batch
            current_batch = []
            current_size = 0
        current_batch.append(graph_json)
        current_size += node_count

    if current_batch:
        yield current_batch

if __name__ == "__main__":
    directory = sys.argv[2]
    fname = os.path.join(directory, "temp_output.json")

    json_data = []
    with open(fname, "r") as file:
        while True:
            obj_str = getobj(file)
            if not obj_str:
                break
            obj_str = loads(obj_str)
            json_data.append(obj_str)

    for batch in get_batch(json_data):
        # Process the batch here
        # Create adjacency matrices and node features for the batch
        pass

    y_pred = model.forward(A, node_features, test_node, test_target, eval=True)
    # Additional processing based on the prediction task

#print(y_pred)

firstlen=len(json_data[0]['nodes'])

for i, flake in enumerate(snowflakes):
    if flake<firstlen:
       node_types=json_data[0]['nodes'][flake]['type']
    else:
       node_types=json_data[1]['nodes'][flake-firstlen]['type']
    if ("MethodDeclaration" in node_types) or ("FieldDeclaration" in node_types):
        print(float(y_pred[i,1]-y_pred[i,0]))
